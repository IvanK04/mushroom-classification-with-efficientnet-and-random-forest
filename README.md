# mushroom-classification-with-efficientnet-and-random-forest

English version:

This project focuses on classifying wild mushroom species based on images, aiming to support the accurate identification of toxic mushrooms. To achieve the best classification performance, four different feature extraction and modeling strategies were implemented and evaluated.

ğŸ§ª Methods Used
1. HOG + Histogram + Random Forest
Features are extracted using Histogram of Oriented Gradients (HOG) and color histograms to capture edge direction and color distribution.

A Random Forest classifier is trained on these handcrafted features.

2. LBP (Local Binary Pattern) + Random Forest
Uses LBP to extract local texture patterns from grayscale images.

Features are fed into a Random Forest for classification.

3. Transfer Learning with EfficientNetB2 + Random Forest
Leverages a pre-trained EfficientNetB2 model to extract deep image features.

These features are passed into a Random Forest to perform classification.

4. Transfer Learning with ResNet-50 + Random Forest
Similar to the above but uses ResNet-50 as the feature extractor.

Combines the power of deep residual networks with a lightweight random forest classifier.

âš™ï¸ Optimization & Enhancements
Hyperparameter tuning for the Random Forest classifier was performed using Optuna, an automated hyperparameter optimization framework.

Data augmentation techniques (such as rotation, flipping, and brightness adjustment) were applied to enhance the diversity of the training dataset and improve model generalization.

PhiÃªn báº£n tiáº¿ng viá»‡t:

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c phÃ¢n loáº¡i cÃ¡c loÃ i náº¥m hoang dÃ£ thÃ´ng qua hÃ¬nh áº£nh, vá»›i má»¥c tiÃªu há»— trá»£ nháº­n dáº¡ng chÃ­nh xÃ¡c cÃ¡c loÃ i náº¥m Ä‘á»™c háº¡i. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u quáº£ phÃ¢n loáº¡i tá»‘t nháº¥t, mÃ¬nh Ä‘Ã£ Ã¡p dá»¥ng bá»‘n phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ Ä‘áº·c trÆ°ng khÃ¡c nhau vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a chÃºng.

ğŸ” CÃ¡c phÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng
1. HOG + Histogram + Random Forest
TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng báº±ng Histogram of Oriented Gradients vÃ  phÃ¢n tÃ­ch táº§n suáº¥t pixel qua histogram mÃ u.

Ãp dá»¥ng Random Forest Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i.

2. LBP (Local Binary Pattern) + Random Forest
Sá»­ dá»¥ng LBP Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng káº¿t cáº¥u cá»¥c bá»™ trÃªn áº£nh xÃ¡m.

Káº¿t há»£p vá»›i Random Forest nháº±m Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a Ä‘áº·c trÆ°ng káº¿t cáº¥u.

3. Transfer Learning vá»›i EfficientNetB2 + Random Forest
Sá»­ dá»¥ng mÃ´ hÃ¬nh EfficientNetB2 Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn ImageNet Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng sÃ¢u (deep features).

Sau Ä‘Ã³ Ä‘Æ°a vÃ o Random Forest Ä‘á»ƒ phÃ¢n loáº¡i.

4. Transfer Learning vá»›i ResNet-50 + Random Forest
TÆ°Æ¡ng tá»± phÆ°Æ¡ng phÃ¡p trÃªn nhÆ°ng thay EfficientNetB2 báº±ng ResNet-50.

ResNet ná»•i báº­t vá»›i kiáº¿n trÃºc residual giÃºp há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng trá»«u tÆ°á»£ng vÃ  á»•n Ä‘á»‹nh.



âš™ï¸ Tá»‘i Æ°u mÃ´ hÃ¬nh vÃ  cáº£i tiáº¿n hiá»‡u suáº¥t
CÃ¡c tham sá»‘ (hyperparameters) cá»§a mÃ´ hÃ¬nh Random Forest Ä‘Æ°á»£c tá»‘i Æ°u tá»± Ä‘á»™ng báº±ng Optuna, nháº±m tÃ¬m ra cáº¥u hÃ¬nh tá»‘t nháº¥t cho tá»«ng phÆ°Æ¡ng phÃ¡p.

BÃªn cáº¡nh Ä‘Ã³, mÃ¬nh cÅ©ng Ã¡p dá»¥ng Data Augmentation (phÃ©p biáº¿n Ä‘á»•i áº£nh nhÆ° xoay, láº­t, thay Ä‘á»•i Ä‘á»™ sÃ¡ng...) Ä‘á»ƒ tÄƒng Ä‘á»™ Ä‘a dáº¡ng cá»§a dá»¯ liá»‡u vÃ  cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh.
